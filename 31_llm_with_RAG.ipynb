{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/hdakhli/mlops-2024/blob/main/31_llm_with_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0cbbae3e38c51a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: langchain-community in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (0.1.60)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (2.7.1)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (8.3.0)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (0.6.6)\r\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (2.31.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.10.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (2.18.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (4.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core langchain-community"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:09:00.400141Z",
     "start_time": "2024-05-28T15:08:55.600243Z"
    }
   },
   "id": "e9d8445e7b4d7588"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tester un LLM avec une question hyper sp√©cifique"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e04b08c39eea43bf"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:09:07.387897Z",
     "start_time": "2024-05-28T15:09:06.825159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q2_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:   65 tensors\n",
      "llama_model_loader: - type q3_K:  160 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 2.63 GiB (3.35 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  2694.32 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '10', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "# Utiliser langchain avec le model llama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama-2-7b-chat.Q2_K.gguf\"\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Vous √™tes un assistant utile. Vous √™tes l√† pour r√©pondre √† mes questions {input}.\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2818.30 ms\n",
      "llama_print_timings:      sample time =      42.61 ms /   141 runs   (    0.30 ms per token,  3309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4534.73 ms /    37 tokens (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:        eval time =   15292.97 ms /   140 runs   (  109.24 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   20399.96 ms /   177 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\nVous √™tes un assistant utile, c\\'est-√†-dire un mod√®le de langage bas√© sur l\\'apprentissage automatique qui est l√† pour vous aider √† r√©soudre des probl√®mes. Voici les r√©ponses aux questions que vous avez formul√©es :\\n\\n* Un effet est une chose qui peut causer un r√©sultat ou un impact. Par exemple, \"Le nouveau m√©dicament a un grand effet sur la sant√©\" ou \"L\\'incendie a eu un grand effet sur les maisons environnantes\".\\nI hope this helps! Let me know if you have any other questions.'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"Qu'est-ce qu'un sans effet ?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:09:39.936799Z",
     "start_time": "2024-05-28T15:09:19.501822Z"
    }
   },
   "id": "32b3a74457e6c622"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Avec du RAG"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a95f47d91247b6"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-chroma in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: llama-index-embeddings-langchain in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.1.2)\r\n",
      "Requirement already satisfied: llama-index in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.10.37)\r\n",
      "Requirement already satisfied: sentence-transformers in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (2.7.0)\r\n",
      "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (0.5.0)\r\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (0.103.2)\r\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (1.26.4)\r\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-embeddings-langchain)\r\n",
      "  Downloading llama_index_core-0.10.39.post1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.2.5)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.12)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.10)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.9.48)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.20)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.22)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.4)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (4.41.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (2.2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (1.4.2)\r\n",
      "Requirement already satisfied: scipy in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (1.11.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (0.23.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\r\n",
      "Requirement already satisfied: requests>=2.28 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.7.1)\r\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.3)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.23.2)\r\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.11.0)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.18.0)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.64.0)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.3)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.9.4)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (29.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.3.0)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.10.3)\r\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.7.1)\r\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.27.0)\r\n",
      "Requirement already satisfied: filelock in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.60)\r\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\r\n",
      "  Downloading openai-1.30.3-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.6)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\r\n",
      "Requirement already satisfied: httpx in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.1.19)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3)\r\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain)\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: pandas in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.1.1)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.3)\r\n",
      "Requirement already satisfied: sympy in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\r\n",
      "Requirement already satisfied: jinja2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.4)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<1,>=0.95.2->langchain-chroma) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: pyproject_hooks in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (2.4)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.29.0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\r\n",
      "Requirement already satisfied: coloredlogs in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\r\n",
      "Requirement already satisfied: protobuf in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.25.3)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.0.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (68.2.0)\r\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\r\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.6)\r\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.18.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (12.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.21.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.3.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.18.2)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (10.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\r\n",
      "Downloading llama_index_core-0.10.39.post1-py3-none-any.whl (15.4 MB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m15.4/15.4 MB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading openai-1.30.3-py3-none-any.whl (320 kB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m320.6/320.6 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: nltk, openai, llama-index-core\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.6.5\r\n",
      "    Uninstalling nltk-3.6.5:\r\n",
      "      Successfully uninstalled nltk-3.6.5\r\n",
      "  Attempting uninstall: openai\r\n",
      "    Found existing installation: openai 0.28.0\r\n",
      "    Uninstalling openai-0.28.0:\r\n",
      "      Successfully uninstalled openai-0.28.0\r\n",
      "Successfully installed llama-index-core-0.10.39.post1 nltk-3.8.1 openai-1.30.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma llama-index-embeddings-langchain llama-index sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:16:50.360828Z",
     "start_time": "2024-05-28T15:16:31.285154Z"
    }
   },
   "id": "deb41191d5b4c5be"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# define embedding function using sentence-transformers/all-mpnet-base-v2 model from HuggingFace\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# load documents using PyPDFLoader\n",
    "PDF_PATH = \"datasets/contrat.pdf\"\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# create vectorstore and store pages into it\n",
    "vectorstore = Chroma.from_documents(pages, embedding=embeddings, persist_directory=\"./db\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:19:31.402218Z",
     "start_time": "2024-05-28T15:19:26.689875Z"
    }
   },
   "id": "acbcfee014a9522e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4780bd8a11d43fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.llamacpp import LlamaCpp\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "model_path = \"llama-2-7b-chat.Q2_K.gguf\"\n",
    "llm = LlamaCpp(model_path=model_path, verbose=False, n_ctx=2048, f16_kv=True)\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "if the information is not in {context}, JUST say: I dont know !\n",
    "You should always respond in french\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:27:49.196372Z",
     "start_time": "2024-05-28T15:27:48.452504Z"
    }
   },
   "id": "52a7103d9b7ef695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "efee7c076b0b016"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Answer: Un contrat est consid√©r√© comme avoir \"without effect\" (Sans Effet in French) cuando :\\n* La date d\\'effet de ce contrat est dans le futur et que vous d√©cidez de vous r√©tracter.\\n* Le v√©hicule √† assurer n\\'est finalement pas achet√©.\\n* Vous vendez le v√©hicule avant que le contrat ne prenne effet.\\n* Vous souscrivez chez nous dans le cadre d\\'une loi Hamon, mais la date d\\'effet de votre contrat que vous nous demandes ne nous permet pas de r√©silier votre contrat chez votre assureur actuel.'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Qu'est-ce qu'un sans effet ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:29:34.703920Z",
     "start_time": "2024-05-28T15:27:53.539662Z"
    }
   },
   "id": "c7283cb2e56a36ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32cc8471f2694870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enrichir la base vectorielle chroma DB par les cours que vous avez eu cette ann√©e\n",
    "# Tester !"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "721a389708180ae9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a06edee44fd2f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
