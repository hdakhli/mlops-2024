{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/hdakhli/mlops-2024/blob/main/31_llm_with_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0cbbae3e38c51a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: langchain-community in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (0.1.60)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (2.7.1)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core) (8.3.0)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (0.6.6)\r\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-community) (2.31.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.10.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (2.18.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (4.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core langchain-community"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:09:00.400141Z",
     "start_time": "2024-05-28T15:08:55.600243Z"
    }
   },
   "id": "e9d8445e7b4d7588"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tester un LLM avec une question hyper spécifique"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e04b08c39eea43bf"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:09:07.387897Z",
     "start_time": "2024-05-28T15:09:06.825159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q2_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:   65 tensors\n",
      "llama_model_loader: - type q3_K:  160 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 2.63 GiB (3.35 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  2694.32 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '10', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "# Utiliser langchain avec le model llama\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama-2-7b-chat.Q2_K.gguf\"\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Vous êtes un assistant utile. Vous êtes là pour répondre à mes questions {input}.\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2818.30 ms\n",
      "llama_print_timings:      sample time =      42.61 ms /   141 runs   (    0.30 ms per token,  3309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4534.73 ms /    37 tokens (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:        eval time =   15292.97 ms /   140 runs   (  109.24 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   20399.96 ms /   177 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\nVous êtes un assistant utile, c\\'est-à-dire un modèle de langage basé sur l\\'apprentissage automatique qui est là pour vous aider à résoudre des problèmes. Voici les réponses aux questions que vous avez formulées :\\n\\n* Un effet est une chose qui peut causer un résultat ou un impact. Par exemple, \"Le nouveau médicament a un grand effet sur la santé\" ou \"L\\'incendie a eu un grand effet sur les maisons environnantes\".\\nI hope this helps! Let me know if you have any other questions.'"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"Qu'est-ce qu'un sans effet ?\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:09:39.936799Z",
     "start_time": "2024-05-28T15:09:19.501822Z"
    }
   },
   "id": "32b3a74457e6c622"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Avec du RAG"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8a95f47d91247b6"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-chroma in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.1.1)\r\n",
      "Requirement already satisfied: llama-index-embeddings-langchain in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.1.2)\r\n",
      "Requirement already satisfied: llama-index in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (0.10.37)\r\n",
      "Requirement already satisfied: sentence-transformers in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (2.7.0)\r\n",
      "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (0.5.0)\r\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (0.103.2)\r\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (0.2.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-chroma) (1.26.4)\r\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-embeddings-langchain)\r\n",
      "  Downloading llama_index_core-0.10.39.post1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.2.5)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.12)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.10)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.9.48)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.20)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.6)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.22)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index) (0.1.4)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (4.41.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (2.2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (1.4.2)\r\n",
      "Requirement already satisfied: scipy in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (1.11.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (0.23.1)\r\n",
      "Requirement already satisfied: Pillow in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\r\n",
      "Requirement already satisfied: requests>=2.28 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.7.1)\r\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.3)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.23.2)\r\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.11.0)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.18.0)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.64.0)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.3)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.9.4)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (29.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.3.0)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.10.3)\r\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.7.1)\r\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.27.0)\r\n",
      "Requirement already satisfied: filelock in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.60)\r\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\r\n",
      "  Downloading openai-1.30.3-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.6.6)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.8)\r\n",
      "Requirement already satisfied: httpx in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.1.19)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.3)\r\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain)\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: pandas in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2.1.1)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.7.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.3)\r\n",
      "Requirement already satisfied: sympy in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\r\n",
      "Requirement already satisfied: jinja2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.9.4)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<1,>=0.95.2->langchain-chroma) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: pyproject_hooks in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (2.4)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.9.0.post0)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.29.0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\r\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (0.14.0)\r\n",
      "Requirement already satisfied: click in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (8.1.7)\r\n",
      "Requirement already satisfied: coloredlogs in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\r\n",
      "Requirement already satisfied: protobuf in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.25.3)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.0.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.24.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.45b0)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (68.2.0)\r\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\r\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.6)\r\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.18.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.0.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (1.0.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (12.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (3.21.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-langchain) (2024.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.3.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.18.2)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (10.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\r\n",
      "Downloading llama_index_core-0.10.39.post1-py3-none-any.whl (15.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.4/15.4 MB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading openai-1.30.3-py3-none-any.whl (320 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m320.6/320.6 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: nltk, openai, llama-index-core\r\n",
      "  Attempting uninstall: nltk\r\n",
      "    Found existing installation: nltk 3.6.5\r\n",
      "    Uninstalling nltk-3.6.5:\r\n",
      "      Successfully uninstalled nltk-3.6.5\r\n",
      "  Attempting uninstall: openai\r\n",
      "    Found existing installation: openai 0.28.0\r\n",
      "    Uninstalling openai-0.28.0:\r\n",
      "      Successfully uninstalled openai-0.28.0\r\n",
      "Successfully installed llama-index-core-0.10.39.post1 nltk-3.8.1 openai-1.30.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma llama-index-embeddings-langchain llama-index sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:16:50.360828Z",
     "start_time": "2024-05-28T15:16:31.285154Z"
    }
   },
   "id": "deb41191d5b4c5be"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a443xq/Documents/GitHub/api-model/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# define embedding function using sentence-transformers/all-mpnet-base-v2 model from HuggingFace\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# load documents using PyPDFLoader\n",
    "PDF_PATH = \"datasets/contrat.pdf\"\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# create vectorstore and store pages into it\n",
    "vectorstore = Chroma.from_documents(pages, embedding=embeddings, persist_directory=\"./db\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:19:31.402218Z",
     "start_time": "2024-05-28T15:19:26.689875Z"
    }
   },
   "id": "acbcfee014a9522e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4780bd8a11d43fc4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.llamacpp import LlamaCpp\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "model_path = \"llama-2-7b-chat.Q2_K.gguf\"\n",
    "llm = LlamaCpp(model_path=model_path, verbose=False, n_ctx=2048, f16_kv=True)\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "if the information is not in {context}, JUST say: I dont know !\n",
    "You should always respond in french\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:27:49.196372Z",
     "start_time": "2024-05-28T15:27:48.452504Z"
    }
   },
   "id": "52a7103d9b7ef695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "efee7c076b0b016"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Answer: Un contrat est considéré comme avoir \"without effect\" (Sans Effet in French) cuando :\\n* La date d\\'effet de ce contrat est dans le futur et que vous décidez de vous rétracter.\\n* Le véhicule à assurer n\\'est finalement pas acheté.\\n* Vous vendez le véhicule avant que le contrat ne prenne effet.\\n* Vous souscrivez chez nous dans le cadre d\\'une loi Hamon, mais la date d\\'effet de votre contrat que vous nous demandes ne nous permet pas de résilier votre contrat chez votre assureur actuel.'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Qu'est-ce qu'un sans effet ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:29:34.703920Z",
     "start_time": "2024-05-28T15:27:53.539662Z"
    }
   },
   "id": "c7283cb2e56a36ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32cc8471f2694870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Enrichir la base vectorielle chroma DB par les cours que vous avez eu cette année\n",
    "# Tester !"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "721a389708180ae9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a06edee44fd2f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
